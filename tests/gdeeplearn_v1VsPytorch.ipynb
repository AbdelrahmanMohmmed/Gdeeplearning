{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9877d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "project_root = os.path.abspath('..')\n",
    "sys.path.append(project_root)\n",
    "from src.gdeeplearn.simpleDL2 import SimpleDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78962189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 08:52:10.499057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757137930.520545    9797 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757137930.526494    9797 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757137930.541609    9797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757137930.541631    9797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757137930.541633    9797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757137930.541635    9797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-06 08:52:10.545970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#laod data\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) , y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):   \n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5f98ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0, Error: 0.42321, Correct: 0.74370 Test-Err:0.32121 Test-Acc:0.84900\n",
      "I: 10, Error: 0.17138, Correct: 0.93300 Test-Err:0.18460 Test-Acc:0.93210\n",
      "I: 20, Error: 0.16118, Correct: 0.93870 Test-Err:0.17341 Test-Acc:0.93720\n",
      "I: 30, Error: 0.15597, Correct: 0.94150 Test-Err:0.16793 Test-Acc:0.94050\n",
      "I: 40, Error: 0.15255, Correct: 0.94330 Test-Err:0.16473 Test-Acc:0.94260\n",
      "I: 50, Error: 0.15003, Correct: 0.94430 Test-Err:0.16250 Test-Acc:0.94300\n",
      "I: 60, Error: 0.14800, Correct: 0.94580 Test-Err:0.16064 Test-Acc:0.94450\n",
      "I: 70, Error: 0.14644, Correct: 0.94670 Test-Err:0.15928 Test-Acc:0.94590\n",
      "I: 80, Error: 0.14518, Correct: 0.94730 Test-Err:0.15814 Test-Acc:0.94630\n",
      "I: 90, Error: 0.14413, Correct: 0.94750 Test-Err:0.15717 Test-Acc:0.94680\n",
      "I: 100, Error: 0.14312, Correct: 0.94850 Test-Err:0.15649 Test-Acc:0.94780\n",
      "I: 110, Error: 0.14227, Correct: 0.94870 Test-Err:0.15568 Test-Acc:0.94820\n",
      "I: 120, Error: 0.14159, Correct: 0.94910 Test-Err:0.15509 Test-Acc:0.94840\n",
      "I: 130, Error: 0.14096, Correct: 0.94930 Test-Err:0.15458 Test-Acc:0.94890\n",
      "I: 140, Error: 0.14039, Correct: 0.95010 Test-Err:0.15410 Test-Acc:0.94930\n",
      "I: 150, Error: 0.13989, Correct: 0.95040 Test-Err:0.15370 Test-Acc:0.94910\n",
      "I: 160, Error: 0.13943, Correct: 0.95080 Test-Err:0.15335 Test-Acc:0.94920\n",
      "I: 170, Error: 0.13903, Correct: 0.95090 Test-Err:0.15289 Test-Acc:0.94940\n",
      "I: 180, Error: 0.13862, Correct: 0.95120 Test-Err:0.15263 Test-Acc:0.95010\n",
      "I: 190, Error: 0.13828, Correct: 0.95110 Test-Err:0.15233 Test-Acc:0.95030\n",
      "I: 200, Error: 0.13796, Correct: 0.95140 Test-Err:0.15203 Test-Acc:0.95030\n",
      "I: 210, Error: 0.13763, Correct: 0.95160 Test-Err:0.15167 Test-Acc:0.95010\n",
      "I: 220, Error: 0.13734, Correct: 0.95190 Test-Err:0.15144 Test-Acc:0.95010\n",
      "I: 230, Error: 0.13708, Correct: 0.95210 Test-Err:0.15115 Test-Acc:0.95060\n",
      "I: 240, Error: 0.13683, Correct: 0.95230 Test-Err:0.15089 Test-Acc:0.95060\n",
      "I: 250, Error: 0.13659, Correct: 0.95240 Test-Err:0.15064 Test-Acc:0.95100\n",
      "I: 260, Error: 0.13637, Correct: 0.95240 Test-Err:0.15043 Test-Acc:0.95120\n",
      "I: 270, Error: 0.13617, Correct: 0.95280 Test-Err:0.15023 Test-Acc:0.95110\n",
      "I: 280, Error: 0.13596, Correct: 0.95300 Test-Err:0.15003 Test-Acc:0.95110\n",
      "I: 290, Error: 0.13578, Correct: 0.95300 Test-Err:0.14984 Test-Acc:0.95120\n",
      "I: 299, Error: 0.13561, Correct: 0.95300 Test-Err:0.14967 Test-Acc:0.95140\n"
     ]
    }
   ],
   "source": [
    "avg_error , avg_accurcy = SimpleDL().GmodelV1(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb85fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class PyTorchNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_labels: int, epochs: int = 300, alpha: float = 0.01, batch_size: int = 32):\n",
    "        super(PyTorchNeuralNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Define layers\n",
    "        self.layer_0_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_1_2 = nn.Linear(hidden_size, num_labels)\n",
    "        \n",
    "        # Initialize weights similar to your implementation (uniform [-0.1, 0.1])\n",
    "        nn.init.uniform_(self.layer_0_1.weight, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.layer_1_2.weight, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.layer_0_1.bias, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.layer_1_2.bias, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.layer_0_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_1_2(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, input_data: np.ndarray, labels: np.ndarray, test_images: np.ndarray = None, test_labels: np.ndarray = None) -> Tuple[float, float]:\n",
    "        \"\"\"Trains a neural network model with one hidden layer using gradient descent.\n",
    "        \n",
    "        Args:\n",
    "            input_data (np.ndarray): Input data with shape (n_samples, n_features).\n",
    "            labels (np.ndarray): Target labels with shape (n_samples, n_labels).\n",
    "            test_images (np.ndarray, optional): Test input data with shape (n_test_samples, n_features). Defaults to input_data.\n",
    "            test_labels (np.ndarray, optional): Test target labels with shape (n_test_samples, n_labels). Defaults to labels.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[float, float]: Average training error and accuracy over the dataset.\n",
    "        \n",
    "        Notes:\n",
    "            Uses PyTorch with mini-batching for training with ReLU activation and MSE loss.\n",
    "            Evaluates on the test set every 10 epochs or on the last epoch.\n",
    "            Results are printed to stdout.\n",
    "        \"\"\"\n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        input_data = torch.from_numpy(input_data).float()\n",
    "        labels = torch.from_numpy(labels).float()\n",
    "        \n",
    "        # Use input_data and labels as test set if test data not provided\n",
    "        if test_images is None or test_labels is None:\n",
    "            test_images = input_data\n",
    "            test_labels = labels\n",
    "        else:\n",
    "            test_images = torch.from_numpy(test_images).float()\n",
    "            test_labels = torch.from_numpy(test_labels).float()\n",
    "        \n",
    "        # Create DataLoaders for batching\n",
    "        train_dataset = TensorDataset(input_data, labels)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(test_images, test_labels)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.alpha)\n",
    "        \n",
    "        total_error, correct_count = 0.0, 0\n",
    "        for j in range(self.epochs):\n",
    "            self.train()  # Set model to training mode\n",
    "            error, correct_cnt = 0.0, 0\n",
    "            for inputs, targets in train_loader:\n",
    "                # Forward pass\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                error += loss.item() * len(inputs)\n",
    "                correct_cnt += int(torch.sum(torch.argmax(outputs, dim=1) == torch.argmax(targets, dim=1)))\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            error /= len(input_data)\n",
    "            correct_cnt /= len(input_data)\n",
    "            total_error += error\n",
    "            correct_count += correct_cnt\n",
    "            print(f\"\\rI: {j}, Error: {error:.5f}, Correct: {correct_cnt:.5f}\", end='')\n",
    "\n",
    "            # Test evaluation every 10 epochs or on the last epoch\n",
    "            if j % 10 == 0 or j == self.epochs - 1:\n",
    "                self.eval()  # Set model to evaluation mode\n",
    "                test_error, test_correct = 0.0, 0\n",
    "                with torch.no_grad():\n",
    "                    for test_inputs, test_targets in test_loader:\n",
    "                        test_outputs = self(test_inputs)\n",
    "                        test_error += criterion(test_outputs, test_targets).item() * len(test_inputs)\n",
    "                        test_correct += int(torch.sum(torch.argmax(test_outputs, dim=1) == torch.argmax(test_targets, dim=1)))\n",
    "                test_error /= len(test_images)\n",
    "                test_accuracy = test_correct / len(test_images)\n",
    "                print(f\" Test-Err:{test_error:.5f} Test-Acc:{test_accuracy:.5f} Correct:{test_correct}\")\n",
    "                self.train()  # Set model back to training mode\n",
    "\n",
    "        avg_error = total_error / self.epochs\n",
    "        avg_accuracy = correct_count / self.epochs\n",
    "        return avg_error, avg_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e153af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0, Error: 0.09382, Correct: 0.19320 Test-Err:0.08774 Test-Acc:0.24120 Correct:2412\n",
      "I: 10, Error: 0.06164, Correct: 0.60840 Test-Err:0.06082 Test-Acc:0.62580 Correct:6258\n",
      "I: 20, Error: 0.05143, Correct: 0.72620 Test-Err:0.05104 Test-Acc:0.72920 Correct:7292\n",
      "I: 30, Error: 0.04467, Correct: 0.78160 Test-Err:0.04433 Test-Acc:0.78280 Correct:7828\n",
      "I: 40, Error: 0.03931, Correct: 0.81550 Test-Err:0.03907 Test-Acc:0.81470 Correct:8147\n",
      "I: 50, Error: 0.03558, Correct: 0.83600 Test-Err:0.03539 Test-Acc:0.83830 Correct:8383\n",
      "I: 60, Error: 0.03287, Correct: 0.85520 Test-Err:0.03272 Test-Acc:0.85690 Correct:8569\n",
      "I: 70, Error: 0.03092, Correct: 0.86790 Test-Err:0.03081 Test-Acc:0.86770 Correct:8677\n",
      "I: 80, Error: 0.02951, Correct: 0.87300 Test-Err:0.02942 Test-Acc:0.87400 Correct:8740\n",
      "I: 90, Error: 0.02846, Correct: 0.87720 Test-Err:0.02839 Test-Acc:0.87830 Correct:8783\n",
      "I: 100, Error: 0.02763, Correct: 0.88030 Test-Err:0.02756 Test-Acc:0.88140 Correct:8814\n",
      "I: 110, Error: 0.02692, Correct: 0.88380 Test-Err:0.02685 Test-Acc:0.88400 Correct:8840\n",
      "I: 120, Error: 0.02628, Correct: 0.88660 Test-Err:0.02622 Test-Acc:0.88760 Correct:8876\n",
      "I: 130, Error: 0.02563, Correct: 0.89040 Test-Err:0.02556 Test-Acc:0.89070 Correct:8907\n",
      "I: 140, Error: 0.02490, Correct: 0.89210 Test-Err:0.02484 Test-Acc:0.89250 Correct:8925\n",
      "I: 150, Error: 0.02402, Correct: 0.89640 Test-Err:0.02394 Test-Acc:0.89570 Correct:8957\n",
      "I: 160, Error: 0.02294, Correct: 0.89960 Test-Err:0.02286 Test-Acc:0.89950 Correct:8995\n",
      "I: 170, Error: 0.02190, Correct: 0.90380 Test-Err:0.02183 Test-Acc:0.90350 Correct:9035\n",
      "I: 180, Error: 0.02111, Correct: 0.90770 Test-Err:0.02105 Test-Acc:0.90840 Correct:9084\n",
      "I: 190, Error: 0.02051, Correct: 0.91020 Test-Err:0.02045 Test-Acc:0.91010 Correct:9101\n",
      "I: 200, Error: 0.02001, Correct: 0.91280 Test-Err:0.01995 Test-Acc:0.91310 Correct:9131\n",
      "I: 210, Error: 0.01958, Correct: 0.91530 Test-Err:0.01953 Test-Acc:0.91540 Correct:9154\n",
      "I: 220, Error: 0.01922, Correct: 0.91650 Test-Err:0.01916 Test-Acc:0.91700 Correct:9170\n",
      "I: 230, Error: 0.01890, Correct: 0.91790 Test-Err:0.01886 Test-Acc:0.91820 Correct:9182\n",
      "I: 240, Error: 0.01863, Correct: 0.91990 Test-Err:0.01859 Test-Acc:0.91960 Correct:9196\n",
      "I: 250, Error: 0.01839, Correct: 0.92100 Test-Err:0.01836 Test-Acc:0.92120 Correct:9212\n",
      "I: 260, Error: 0.01818, Correct: 0.92120 Test-Err:0.01814 Test-Acc:0.92180 Correct:9218\n",
      "I: 270, Error: 0.01797, Correct: 0.92230 Test-Err:0.01794 Test-Acc:0.92310 Correct:9231\n",
      "I: 280, Error: 0.01779, Correct: 0.92400 Test-Err:0.01775 Test-Acc:0.92370 Correct:9237\n",
      "I: 290, Error: 0.01761, Correct: 0.92430 Test-Err:0.01758 Test-Acc:0.92430 Correct:9243\n",
      "I: 299, Error: 0.01747, Correct: 0.92440 Test-Err:0.01743 Test-Acc:0.92440 Correct:9244\n"
     ]
    }
   ],
   "source": [
    "model = PyTorchNeuralNetwork(input_size=784, hidden_size=10, num_labels=10, epochs=300, alpha=0.01, batch_size=32)\n",
    "avg_error, avg_accuracy = model.train_model(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
